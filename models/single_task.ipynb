{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T00:16:22.135945Z",
     "start_time": "2019-11-28T00:16:22.132689Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import io\n",
    "# from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T21:39:46.382701Z",
     "start_time": "2019-11-27T21:39:45.119864Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/sean/anaconda3/envs/metis/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/sean/anaconda3/envs/metis/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/sean/anaconda3/envs/metis/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/sean/anaconda3/envs/metis/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/sean/anaconda3/envs/metis/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/sean/anaconda3/envs/metis/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T22:40:44.921847Z",
     "start_time": "2019-11-27T22:40:44.916225Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Metrics(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "         self.val_f1s = []\n",
    "         self.val_recalls = []\n",
    "         self.val_precisions = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "         val_predict = (np.asarray(self.model.predict(self.model.validation_data[0]))).round()\n",
    "         val_targ = self.model.validation_data[1]\n",
    "         _val_f1 = f1_score(val_targ, val_predict)\n",
    "         _val_recall = recall_score(val_targ, val_predict)\n",
    "         _val_precision = precision_score(val_targ, val_predict)\n",
    "         self.val_f1s.append(_val_f1)\n",
    "         self.val_recalls.append(_val_recall)\n",
    "         self.val_precisions.append(_val_precision)\n",
    "         print(' — val_f1: {0:f} — val_precision: {1:f} — val_recall {2:f}'.format(_val_f1, _val_precision, _val_recall))\n",
    "         return\n",
    "\n",
    "metrics = Metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T21:39:47.719199Z",
     "start_time": "2019-11-27T21:39:47.599266Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sean/CloudStation/Metis/projects/project5\r\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/Users/sean/CloudStation/Metis/projects/project5')\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T21:40:00.304719Z",
     "start_time": "2019-11-27T21:39:48.960807Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "raw_data = './data/raw/tox21/'\n",
    "y_tr = pd.read_csv(raw_data+'tox21_labels_train.csv.gz', index_col=0, compression=\"gzip\")\n",
    "y_te = pd.read_csv(raw_data+'tox21_labels_test.csv.gz', index_col=0, compression=\"gzip\")\n",
    "x_tr_dense = pd.read_csv(raw_data+'tox21_dense_train.csv.gz', index_col=0, compression=\"gzip\").values\n",
    "x_te_dense = pd.read_csv(raw_data+'tox21_dense_test.csv.gz', index_col=0, compression=\"gzip\").values\n",
    "x_tr_sparse = io.mmread(raw_data+'tox21_sparse_train.mtx.gz').tocsc()\n",
    "x_te_sparse = io.mmread(raw_data+'tox21_sparse_test.mtx.gz').tocsc()\n",
    "# filter out very sparse features\n",
    "sparse_col_idx = ((x_tr_sparse > 0).mean(0) > 0.05).A.ravel()\n",
    "x_tr = np.hstack([x_tr_dense, x_tr_sparse[:, sparse_col_idx].A])\n",
    "x_te = np.hstack([x_te_dense, x_te_sparse[:, sparse_col_idx].A])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Choose A Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T21:40:01.412521Z",
     "start_time": "2019-11-27T21:40:01.408046Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NR.AhR', 'NR.AR', 'NR.AR.LBD', 'NR.Aromatase', 'NR.ER', 'NR.ER.LBD',\n",
       "       'NR.PPAR.gamma', 'SR.ARE', 'SR.ATAD5', 'SR.HSE', 'SR.MMP', 'SR.p53'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The Random Forest example loops through all the targets.  I'll pick only the first one for the DNN MVP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T21:40:03.447136Z",
     "start_time": "2019-11-27T21:40:03.208160Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8441, 1644)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for target in y_tr.columns:\n",
    "target = 'NR.AhR'\n",
    "rows_tr = np.isfinite(y_tr[target]).values\n",
    "rows_te = np.isfinite(y_te[target]).values\n",
    "x,y = x_tr[rows_tr], y_tr[target][rows_tr]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Address Class Imbalance\n",
    "Oversampling Documentation:\n",
    "https://imbalanced-learn.readthedocs.io/en/stable/over_sampling.html\n",
    "\n",
    "\"While the `RandomOverSampler` is over-sampling by duplicating some of the original samples of the minority class, `SMOTE` and `ADASYN` generate new samples in by interpolation. However, the samples used to interpolate/generate new synthetic samples differ. In fact, `ADASYN` focuses on generating samples next to the original samples which are wrongly classified using a k-Nearest Neighbors classifier while the basic implementation of `SMOTE` will not make any distinction between easy and hard samples to be classified using the nearest neighbors rule. Therefore, the decision function found during training will be different among the algorithms.\"\n",
    "\n",
    "**I decided that over-sampling using synthetic methods is probably not legitimate because it is creating new \"samples\", i.e. chemicals with properties (feature values) that do not represent real chemical structures.  Though I tried using SMOTE and got reasonably similar results, I think the approach is technically dubious.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T21:40:05.263447Z",
     "start_time": "2019-11-27T21:40:04.959970Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler #, SMOTE, ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T21:40:09.024048Z",
     "start_time": "2019-11-27T21:40:09.018100Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    7460\n",
       "1.0     981\n",
       "Name: NR.AhR, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To keep the class proportions the same use the stratify parameter: [source](https://stats.stackexchange.com/questions/394056/splitting-into-train-and-test-sets-keeping-class-proportions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T21:40:12.947753Z",
     "start_time": "2019-11-27T21:40:12.882476Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x, y, stratify=y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T21:40:16.494367Z",
     "start_time": "2019-11-27T21:40:16.489234Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    1493\n",
       "1.0     196\n",
       "Name: NR.AhR, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T21:40:27.235060Z",
     "start_time": "2019-11-27T21:40:26.783733Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=0)\n",
    "# ros = SMOTE(random_state=42)   # See comment above - I don't believe this is legitimate.\n",
    "x_resampled, y_resampled = ros.fit_sample(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T21:40:28.839791Z",
     "start_time": "2019-11-27T21:40:28.833025Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    5967\n",
       "0.0    5967\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_resampled).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T21:40:30.620064Z",
     "start_time": "2019-11-27T21:40:30.616495Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11934, 1644)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_resampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Neural Network\n",
    "\n",
    "Following the desciption in section 2.2.4 of the [DeepTox article](https://www.frontiersin.org/articles/10.3389/fenvs.2015.00080/full), I tried to use intermediate values in [Table 2](https://www.frontiersin.org/articles/10.3389/fenvs.2015.00080/full#T2) to build the neural network:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following [this question/answer](https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model) and [this question/answer](https://stackoverflow.com/questions/54065733/how-to-employ-the-scikit-learn-evaluation-metrics-functions-with-keras-in-python) to implement usage of recall in model training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T00:34:43.416576Z",
     "start_time": "2019-11-28T00:34:43.408732Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "#     return recall_score(y_true.eval(),y_pred.eval())\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T00:34:48.897932Z",
     "start_time": "2019-11-28T00:34:48.720211Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "h1_sigmoid_activation (Dense (None, 1024)              1684480   \n",
      "_________________________________________________________________\n",
      "Dropout1 (Dropout)           (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "h2_sigmoid_activation (Dense (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "Dropout2 (Dropout)           (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "h3_sigmoid_activation (Dense (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "Dropout3 (Dropout)           (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 3,784,705\n",
      "Trainable params: 3,784,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "drop_out=0.5    # DeepTox range: 0.5, 0.2, 0\n",
    "L2_reg = 0.0001 # Default = 0.01\n",
    "layers = 3      # DeepTox range: 1, 2, 3, 4\n",
    "act = 'sigmoid' # Consider sigmoid and tanh\n",
    "neurons = 1024  # DeepTox range: 1024, 2048, 4096, 8192, 16384\n",
    "# Info on decay: https://datascience.stackexchange.com/questions/26112/decay-parameter-in-keras-optimizers\n",
    "decay = 0       # DeepTox range: 10^-4, 10^-5, 10^-6\n",
    "learn_rate = 0.1  #Research appropriate range\n",
    "DNN = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=x.shape[1:],name='Input_Layer')\n",
    "])\n",
    "for i in range(1,layers+1):\n",
    "    DNN.add(Dense(units=neurons, activation=act,\\\n",
    "                  name='h'+str(i)+'_'+act+'_activation',\\\n",
    "                  kernel_regularizer=keras.regularizers.l2(L2_reg)))\n",
    "    DNN.add(Dropout(rate=drop_out,name='Dropout'+str(i)))\n",
    "DNN.add(Dense(units=1, activation='sigmoid'))\n",
    "keras.optimizers.Adam(lr=learn_rate, beta_1=0.9,\\\n",
    "                      beta_2=0.999, decay=decay, amsgrad=False)\n",
    "DNN.compile(optimizer='adam', loss='binary_crossentropy',\\\n",
    "            metrics=['accuracy',recall_m,f1])\n",
    "DNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T23:08:36.626287Z",
     "start_time": "2019-11-27T23:07:45.394287Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11934 samples, validate on 1689 samples\n",
      "Epoch 1/100\n",
      "11934/11934 [==============================] - 2s 184us/step - loss: 0.6167 - acc: 0.7585 - recall_m: 0.7984 - val_loss: 0.6145 - val_acc: 0.7863 - val_recall_m: 0.7273\n",
      "Epoch 2/100\n",
      "11934/11934 [==============================] - 2s 191us/step - loss: 0.6193 - acc: 0.7567 - recall_m: 0.7973 - val_loss: 0.6140 - val_acc: 0.7880 - val_recall_m: 0.7273\n",
      "Epoch 3/100\n",
      "11934/11934 [==============================] - 2s 197us/step - loss: 0.6191 - acc: 0.7592 - recall_m: 0.7916 - val_loss: 0.6139 - val_acc: 0.7886 - val_recall_m: 0.7273\n",
      "Epoch 4/100\n",
      "11934/11934 [==============================] - 3s 213us/step - loss: 0.6182 - acc: 0.7617 - recall_m: 0.8044 - val_loss: 0.6138 - val_acc: 0.7874 - val_recall_m: 0.7273\n",
      "Epoch 5/100\n",
      "11934/11934 [==============================] - 2s 209us/step - loss: 0.6192 - acc: 0.7547 - recall_m: 0.7921 - val_loss: 0.6136 - val_acc: 0.7874 - val_recall_m: 0.7273\n",
      "Epoch 6/100\n",
      "11934/11934 [==============================] - 3s 213us/step - loss: 0.6152 - acc: 0.7564 - recall_m: 0.7962 - val_loss: 0.6133 - val_acc: 0.7874 - val_recall_m: 0.7273\n",
      "Epoch 7/100\n",
      "11934/11934 [==============================] - 3s 211us/step - loss: 0.6147 - acc: 0.7624 - recall_m: 0.7991 - val_loss: 0.6128 - val_acc: 0.7898 - val_recall_m: 0.7229\n",
      "Epoch 8/100\n",
      "11934/11934 [==============================] - 3s 215us/step - loss: 0.6160 - acc: 0.7572 - recall_m: 0.7926 - val_loss: 0.6125 - val_acc: 0.7904 - val_recall_m: 0.7229\n",
      "Epoch 9/100\n",
      "11934/11934 [==============================] - 3s 223us/step - loss: 0.6159 - acc: 0.7586 - recall_m: 0.7910 - val_loss: 0.6123 - val_acc: 0.7910 - val_recall_m: 0.7229\n",
      "Epoch 10/100\n",
      "11934/11934 [==============================] - 3s 219us/step - loss: 0.6125 - acc: 0.7596 - recall_m: 0.7994 - val_loss: 0.6120 - val_acc: 0.7916 - val_recall_m: 0.7229\n",
      "Epoch 11/100\n",
      "11934/11934 [==============================] - 3s 217us/step - loss: 0.6160 - acc: 0.7560 - recall_m: 0.7924 - val_loss: 0.6116 - val_acc: 0.7916 - val_recall_m: 0.7229\n",
      "Epoch 12/100\n",
      "11934/11934 [==============================] - 3s 223us/step - loss: 0.6195 - acc: 0.7551 - recall_m: 0.7892 - val_loss: 0.6114 - val_acc: 0.7916 - val_recall_m: 0.7229\n",
      "Epoch 13/100\n",
      "11934/11934 [==============================] - 3s 221us/step - loss: 0.6194 - acc: 0.7562 - recall_m: 0.7972 - val_loss: 0.6114 - val_acc: 0.7916 - val_recall_m: 0.7229\n",
      "Epoch 14/100\n",
      "11934/11934 [==============================] - 3s 217us/step - loss: 0.6194 - acc: 0.7562 - recall_m: 0.7957 - val_loss: 0.6107 - val_acc: 0.7916 - val_recall_m: 0.7229\n",
      "Epoch 15/100\n",
      "11934/11934 [==============================] - 3s 223us/step - loss: 0.6125 - acc: 0.7609 - recall_m: 0.7977 - val_loss: 0.6105 - val_acc: 0.7916 - val_recall_m: 0.7229\n",
      "Epoch 16/100\n",
      "11934/11934 [==============================] - 3s 216us/step - loss: 0.6099 - acc: 0.7654 - recall_m: 0.8039 - val_loss: 0.6104 - val_acc: 0.7916 - val_recall_m: 0.7229\n",
      "Epoch 17/100\n",
      "11934/11934 [==============================] - 3s 229us/step - loss: 0.6161 - acc: 0.7559 - recall_m: 0.7919 - val_loss: 0.6098 - val_acc: 0.7922 - val_recall_m: 0.7229\n",
      "Epoch 18/100\n",
      "11934/11934 [==============================] - 3s 221us/step - loss: 0.6188 - acc: 0.7614 - recall_m: 0.7936 - val_loss: 0.6099 - val_acc: 0.7922 - val_recall_m: 0.7229\n",
      "Epoch 19/100\n",
      "11934/11934 [==============================] - 3s 224us/step - loss: 0.6194 - acc: 0.7517 - recall_m: 0.7862 - val_loss: 0.6098 - val_acc: 0.7922 - val_recall_m: 0.7229\n",
      "Epoch 20/100\n",
      "11934/11934 [==============================] - 3s 225us/step - loss: 0.6177 - acc: 0.7575 - recall_m: 0.7935 - val_loss: 0.6099 - val_acc: 0.7922 - val_recall_m: 0.7229\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00020: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x150c0aef0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DNN.fit(\n",
    "    x_resampled, y_resampled, batch_size=512, epochs=100,\\\n",
    "    validation_data=(x_val,y_val), verbose=1,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(patience=16,verbose=1,\\\n",
    "                                      restore_best_weights=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(factor=0.5,patience=3,verbose=1)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T23:08:48.779512Z",
     "start_time": "2019-11-27T23:08:48.680077Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         NR.AhR: 0.86169\n"
     ]
    }
   ],
   "source": [
    "auc_te = roc_auc_score(y_te[target][rows_te], DNN.predict(x_te[rows_te]))\n",
    "print(\"%15s: %3.5f\" % (target, auc_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T23:08:52.442020Z",
     "start_time": "2019-11-27T23:08:52.368444Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['TN' 'FP']\n",
      " ['FN' 'TP']]\n",
      "[[401 136]\n",
      " [ 13  60]]\n"
     ]
    }
   ],
   "source": [
    "y_testing=y_te[target][~np.isnan(y_te[target])]\n",
    "y_hat_testing=DNN.predict_classes(x_te[rows_te])\n",
    "print(np.array([['TN','FP'],['FN','TP']]))\n",
    "print(confusion_matrix(y_testing,y_hat_testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T23:08:57.399782Z",
     "start_time": "2019-11-27T23:08:57.390127Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.44609665427509304\n",
      "recall: 0.821917808219178\n",
      "precision: 0.30612244897959184\n"
     ]
    }
   ],
   "source": [
    "print('f1:',f1_score(y_testing,y_hat_testing))\n",
    "print('recall:',recall_score(y_testing,y_hat_testing))\n",
    "print('precision:',precision_score(y_testing,y_hat_testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T21:42:07.366629Z",
     "start_time": "2019-11-27T21:42:07.360560Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    537\n",
       "1.0     73\n",
       "Name: NR.AhR, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_te[target][rows_te].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T21:03:32.591188Z",
     "start_time": "2019-11-27T21:03:32.587209Z"
    }
   },
   "outputs": [],
   "source": [
    "537/(537+73)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment to save model.  Last ROC_UAC = 0.86068"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T23:22:47.686337Z",
     "start_time": "2019-11-27T23:22:47.348469Z"
    }
   },
   "outputs": [],
   "source": [
    "# DNN.save('./models/saves/first_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
