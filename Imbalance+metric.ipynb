{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T03:19:28.055564Z",
     "start_time": "2019-12-02T03:19:27.129425Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import io\n",
    "# from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "from src.helper_functions import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T03:19:29.312588Z",
     "start_time": "2019-12-02T03:19:28.057850Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/sean/anaconda3/envs/metis/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/sean/anaconda3/envs/metis/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/sean/anaconda3/envs/metis/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/sean/anaconda3/envs/metis/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/sean/anaconda3/envs/metis/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/sean/anaconda3/envs/metis/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T03:19:41.719157Z",
     "start_time": "2019-12-02T03:19:30.367892Z"
    }
   },
   "outputs": [],
   "source": [
    "x_tr, y_tr, x_te, y_te = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose A Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T03:19:42.702864Z",
     "start_time": "2019-12-02T03:19:42.698582Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NR.AhR', 'NR.AR', 'NR.AR.LBD', 'NR.Aromatase', 'NR.ER', 'NR.ER.LBD',\n",
       "       'NR.PPAR.gamma', 'SR.ARE', 'SR.ATAD5', 'SR.HSE', 'SR.MMP', 'SR.p53'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest example loops through all the targets.  I'll pick only the first one for the DNN MVP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T03:20:12.810879Z",
     "start_time": "2019-12-02T03:20:12.623136Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8441, 1644)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for target in y_tr.columns:\n",
    "target = 'NR.AhR'\n",
    "rows_tr = np.isfinite(y_tr[target]).values\n",
    "rows_te = np.isfinite(y_te[target]).values\n",
    "x,y = x_tr[rows_tr], y_tr[target][rows_tr]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Address Class Imbalance\n",
    "Oversampling Documentation:\n",
    "https://imbalanced-learn.readthedocs.io/en/stable/over_sampling.html\n",
    "\n",
    "\"While the `RandomOverSampler` is over-sampling by duplicating some of the original samples of the minority class, `SMOTE` and `ADASYN` generate new samples in by interpolation. However, the samples used to interpolate/generate new synthetic samples differ. In fact, `ADASYN` focuses on generating samples next to the original samples which are wrongly classified using a k-Nearest Neighbors classifier while the basic implementation of `SMOTE` will not make any distinction between easy and hard samples to be classified using the nearest neighbors rule. Therefore, the decision function found during training will be different among the algorithms.\"\n",
    "\n",
    "**I decided that over-sampling using synthetic methods is probably not legitimate because it is creating new \"samples\", i.e. chemicals with properties (feature values) that do not represent real chemical structures.  Though I tried using SMOTE and got reasonably similar results, I think the approach is technically dubious.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T03:20:49.511205Z",
     "start_time": "2019-12-02T03:20:49.388586Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler #, SMOTE, ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T03:20:50.523736Z",
     "start_time": "2019-12-02T03:20:50.516442Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    7460\n",
       "1.0     981\n",
       "Name: NR.AhR, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep the class proportions the same use the stratify parameter: [source](https://stats.stackexchange.com/questions/394056/splitting-into-train-and-test-sets-keeping-class-proportions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T03:20:51.581684Z",
     "start_time": "2019-12-02T03:20:51.548768Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x, y, stratify=y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T03:20:52.473949Z",
     "start_time": "2019-12-02T03:20:52.468611Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    1493\n",
       "1.0     196\n",
       "Name: NR.AhR, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T03:20:53.303924Z",
     "start_time": "2019-12-02T03:20:53.213837Z"
    }
   },
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=0)\n",
    "# ros = SMOTE(random_state=42)   # See comment above - I don't believe using SMOTE is legitimate.\n",
    "x_resampled, y_resampled = ros.fit_sample(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T03:20:54.283584Z",
     "start_time": "2019-12-02T03:20:54.272067Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    5967\n",
       "0.0    5967\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_resampled).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T03:20:55.152609Z",
     "start_time": "2019-12-02T03:20:55.149010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11934, 1644)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_resampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Neural Network\n",
    "\n",
    "Following the desciption in section 2.2.4 of the [DeepTox article](https://www.frontiersin.org/articles/10.3389/fenvs.2015.00080/full), I tried to use intermediate values in [Table 2](https://www.frontiersin.org/articles/10.3389/fenvs.2015.00080/full#T2) to build the neural network:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following [this question/answer](https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model) to implement usage of recall in model training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T03:56:09.283286Z",
     "start_time": "2019-11-30T03:56:09.279390Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T03:56:09.467377Z",
     "start_time": "2019-11-30T03:56:09.285509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sean/anaconda3/envs/metis/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/sean/anaconda3/envs/metis/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "h1_sigmoid_activation (Dense (None, 1024)              1684480   \n",
      "_________________________________________________________________\n",
      "Dropout1 (Dropout)           (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "h2_sigmoid_activation (Dense (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "Dropout2 (Dropout)           (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "h3_sigmoid_activation (Dense (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "Dropout3 (Dropout)           (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 3,784,705\n",
      "Trainable params: 3,784,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "drop_out=0.5    # DeepTox range: 0.5, 0.2, 0\n",
    "L2_reg = 0.0001 # Default = 0.01\n",
    "layers = 3      # DeepTox range: 1, 2, 3, 4\n",
    "act = 'sigmoid' # Consider sigmoid and tanh\n",
    "neurons = 1024  # DeepTox range: 1024, 2048, 4096, 8192, 16384\n",
    "decay = 0       # DeepTox range: 10^-4, 10^-5, 10^-6\n",
    "learn_rate = 0.1  #Research appropriate range\n",
    "DNN = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=x.shape[1:],name='Input_Layer')\n",
    "])\n",
    "for i in range(1,layers+1):\n",
    "    DNN.add(Dense(units=neurons, activation=act,\\\n",
    "                  name='h'+str(i)+'_'+act+'_activation',\\\n",
    "                  kernel_regularizer=keras.regularizers.l2(L2_reg)))\n",
    "    DNN.add(Dropout(rate=drop_out,name='Dropout'+str(i)))\n",
    "DNN.add(Dense(units=1, activation='sigmoid'))\n",
    "keras.optimizers.Adam(lr=learn_rate, beta_1=0.9,\\\n",
    "                      beta_2=0.999, decay=decay, amsgrad=False)\n",
    "# Info on decay: https://datascience.stackexchange.com/questions/26112/decay-parameter-in-keras-optimizers\n",
    "DNN.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',recall_m])\n",
    "DNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T03:58:22.663543Z",
     "start_time": "2019-11-30T03:56:09.469123Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sean/anaconda3/envs/metis/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 11934 samples, validate on 1689 samples\n",
      "Epoch 1/100\n",
      "11934/11934 [==============================] - 3s 253us/step - loss: 1.1277 - acc: 0.5296 - recall_m: 0.5338 - val_loss: 0.8682 - val_acc: 0.5258 - val_recall_m: 0.8159\n",
      "Epoch 2/100\n",
      "11934/11934 [==============================] - 2s 196us/step - loss: 0.8542 - acc: 0.6269 - recall_m: 0.6373 - val_loss: 0.7666 - val_acc: 0.6945 - val_recall_m: 0.7009\n",
      "Epoch 3/100\n",
      "11934/11934 [==============================] - 2s 197us/step - loss: 0.7696 - acc: 0.6786 - recall_m: 0.7116 - val_loss: 0.7936 - val_acc: 0.6726 - val_recall_m: 0.8010\n",
      "Epoch 4/100\n",
      "11934/11934 [==============================] - 2s 207us/step - loss: 0.7430 - acc: 0.6878 - recall_m: 0.7296 - val_loss: 0.6907 - val_acc: 0.7395 - val_recall_m: 0.7317\n",
      "Epoch 5/100\n",
      "11934/11934 [==============================] - 2s 208us/step - loss: 0.7288 - acc: 0.6957 - recall_m: 0.7288 - val_loss: 0.6451 - val_acc: 0.7442 - val_recall_m: 0.7131\n",
      "Epoch 6/100\n",
      "11934/11934 [==============================] - 2s 208us/step - loss: 0.7056 - acc: 0.7102 - recall_m: 0.7439 - val_loss: 0.6186 - val_acc: 0.7655 - val_recall_m: 0.6857\n",
      "Epoch 7/100\n",
      "11934/11934 [==============================] - 2s 204us/step - loss: 0.6912 - acc: 0.7107 - recall_m: 0.7408 - val_loss: 0.6246 - val_acc: 0.7987 - val_recall_m: 0.6633\n",
      "Epoch 8/100\n",
      "11934/11934 [==============================] - 2s 209us/step - loss: 0.6790 - acc: 0.7136 - recall_m: 0.7519 - val_loss: 0.6233 - val_acc: 0.7898 - val_recall_m: 0.7294\n",
      "Epoch 9/100\n",
      "11934/11934 [==============================] - 2s 209us/step - loss: 0.6701 - acc: 0.7227 - recall_m: 0.7468 - val_loss: 0.6880 - val_acc: 0.6489 - val_recall_m: 0.8831\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 10/100\n",
      "11934/11934 [==============================] - 2s 207us/step - loss: 0.6526 - acc: 0.7226 - recall_m: 0.7606 - val_loss: 0.6369 - val_acc: 0.7815 - val_recall_m: 0.7191\n",
      "Epoch 11/100\n",
      "11934/11934 [==============================] - 2s 208us/step - loss: 0.6377 - acc: 0.7410 - recall_m: 0.7650 - val_loss: 0.5767 - val_acc: 0.8094 - val_recall_m: 0.6883\n",
      "Epoch 12/100\n",
      "11934/11934 [==============================] - 3s 211us/step - loss: 0.6281 - acc: 0.7402 - recall_m: 0.7645 - val_loss: 0.6731 - val_acc: 0.6359 - val_recall_m: 0.8789\n",
      "Epoch 13/100\n",
      "11934/11934 [==============================] - 3s 217us/step - loss: 0.6173 - acc: 0.7480 - recall_m: 0.7738 - val_loss: 0.6001 - val_acc: 0.7780 - val_recall_m: 0.7256\n",
      "Epoch 14/100\n",
      "11934/11934 [==============================] - 3s 213us/step - loss: 0.6159 - acc: 0.7463 - recall_m: 0.7773 - val_loss: 0.5911 - val_acc: 0.7359 - val_recall_m: 0.7999\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 15/100\n",
      "11934/11934 [==============================] - 3s 213us/step - loss: 0.6089 - acc: 0.7485 - recall_m: 0.7760 - val_loss: 0.5308 - val_acc: 0.8218 - val_recall_m: 0.6686\n",
      "Epoch 16/100\n",
      "11934/11934 [==============================] - 3s 213us/step - loss: 0.5972 - acc: 0.7553 - recall_m: 0.7780 - val_loss: 0.6150 - val_acc: 0.7188 - val_recall_m: 0.8220\n",
      "Epoch 17/100\n",
      "11934/11934 [==============================] - 3s 213us/step - loss: 0.5878 - acc: 0.7605 - recall_m: 0.7880 - val_loss: 0.5946 - val_acc: 0.7223 - val_recall_m: 0.8143\n",
      "Epoch 18/100\n",
      "11934/11934 [==============================] - 3s 214us/step - loss: 0.5878 - acc: 0.7588 - recall_m: 0.7853 - val_loss: 0.5849 - val_acc: 0.7454 - val_recall_m: 0.7764\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 19/100\n",
      "11934/11934 [==============================] - 3s 218us/step - loss: 0.5778 - acc: 0.7643 - recall_m: 0.8007 - val_loss: 0.5446 - val_acc: 0.8135 - val_recall_m: 0.7050\n",
      "Epoch 20/100\n",
      "11934/11934 [==============================] - 3s 212us/step - loss: 0.5671 - acc: 0.7692 - recall_m: 0.7847 - val_loss: 0.5444 - val_acc: 0.8153 - val_recall_m: 0.6931\n",
      "Epoch 21/100\n",
      "11934/11934 [==============================] - 3s 215us/step - loss: 0.5682 - acc: 0.7680 - recall_m: 0.8011 - val_loss: 0.5489 - val_acc: 0.8135 - val_recall_m: 0.6882\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 22/100\n",
      "11934/11934 [==============================] - 3s 218us/step - loss: 0.5638 - acc: 0.7696 - recall_m: 0.7919 - val_loss: 0.5393 - val_acc: 0.8218 - val_recall_m: 0.6956\n",
      "Epoch 23/100\n",
      "11934/11934 [==============================] - 3s 226us/step - loss: 0.5629 - acc: 0.7724 - recall_m: 0.8011 - val_loss: 0.5670 - val_acc: 0.7851 - val_recall_m: 0.7594\n",
      "Epoch 24/100\n",
      "11934/11934 [==============================] - 3s 216us/step - loss: 0.5600 - acc: 0.7756 - recall_m: 0.7938 - val_loss: 0.5566 - val_acc: 0.8147 - val_recall_m: 0.6927\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 25/100\n",
      "11934/11934 [==============================] - 3s 218us/step - loss: 0.5571 - acc: 0.7763 - recall_m: 0.7924 - val_loss: 0.5474 - val_acc: 0.8176 - val_recall_m: 0.6927\n",
      "Epoch 26/100\n",
      "11934/11934 [==============================] - 3s 220us/step - loss: 0.5519 - acc: 0.7770 - recall_m: 0.8033 - val_loss: 0.5521 - val_acc: 0.8022 - val_recall_m: 0.7277\n",
      "Epoch 27/100\n",
      "11934/11934 [==============================] - 3s 224us/step - loss: 0.5503 - acc: 0.7794 - recall_m: 0.7981 - val_loss: 0.5450 - val_acc: 0.8182 - val_recall_m: 0.7050\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 28/100\n",
      "11934/11934 [==============================] - 3s 222us/step - loss: 0.5503 - acc: 0.7780 - recall_m: 0.8048 - val_loss: 0.5397 - val_acc: 0.8212 - val_recall_m: 0.7005\n",
      "Epoch 29/100\n",
      "11934/11934 [==============================] - 3s 222us/step - loss: 0.5488 - acc: 0.7756 - recall_m: 0.7970 - val_loss: 0.5419 - val_acc: 0.8200 - val_recall_m: 0.7005\n",
      "Epoch 30/100\n",
      "11934/11934 [==============================] - 3s 221us/step - loss: 0.5479 - acc: 0.7826 - recall_m: 0.8047 - val_loss: 0.5464 - val_acc: 0.8153 - val_recall_m: 0.7050\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 31/100\n",
      "11934/11934 [==============================] - 3s 225us/step - loss: 0.5493 - acc: 0.7781 - recall_m: 0.8003 - val_loss: 0.5429 - val_acc: 0.8176 - val_recall_m: 0.7139\n",
      "Epoch 32/100\n",
      "11934/11934 [==============================] - 3s 235us/step - loss: 0.5509 - acc: 0.7759 - recall_m: 0.7940 - val_loss: 0.5401 - val_acc: 0.8218 - val_recall_m: 0.7050\n",
      "Epoch 33/100\n",
      "11934/11934 [==============================] - 3s 216us/step - loss: 0.5476 - acc: 0.7775 - recall_m: 0.7935 - val_loss: 0.5407 - val_acc: 0.8206 - val_recall_m: 0.7005\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 34/100\n",
      "11934/11934 [==============================] - 3s 213us/step - loss: 0.5488 - acc: 0.7760 - recall_m: 0.7964 - val_loss: 0.5430 - val_acc: 0.8153 - val_recall_m: 0.7188\n",
      "Epoch 35/100\n",
      "11934/11934 [==============================] - 2s 208us/step - loss: 0.5448 - acc: 0.7822 - recall_m: 0.8061 - val_loss: 0.5419 - val_acc: 0.8176 - val_recall_m: 0.7094\n",
      "Epoch 36/100\n",
      "11934/11934 [==============================] - 2s 209us/step - loss: 0.5427 - acc: 0.7862 - recall_m: 0.8076 - val_loss: 0.5402 - val_acc: 0.8206 - val_recall_m: 0.7005\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 37/100\n",
      "11934/11934 [==============================] - 3s 220us/step - loss: 0.5470 - acc: 0.7783 - recall_m: 0.7990 - val_loss: 0.5397 - val_acc: 0.8212 - val_recall_m: 0.7005\n",
      "Epoch 38/100\n",
      "11934/11934 [==============================] - 3s 218us/step - loss: 0.5465 - acc: 0.7838 - recall_m: 0.8038 - val_loss: 0.5398 - val_acc: 0.8206 - val_recall_m: 0.7005\n",
      "Epoch 39/100\n",
      "11934/11934 [==============================] - 3s 210us/step - loss: 0.5460 - acc: 0.7852 - recall_m: 0.8041 - val_loss: 0.5409 - val_acc: 0.8206 - val_recall_m: 0.7005\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11934/11934 [==============================] - 2s 207us/step - loss: 0.5472 - acc: 0.7757 - recall_m: 0.7984 - val_loss: 0.5412 - val_acc: 0.8206 - val_recall_m: 0.7005\n",
      "Epoch 41/100\n",
      "11934/11934 [==============================] - 2s 207us/step - loss: 0.5465 - acc: 0.7841 - recall_m: 0.8074 - val_loss: 0.5410 - val_acc: 0.8206 - val_recall_m: 0.7005\n",
      "Epoch 42/100\n",
      "11934/11934 [==============================] - 2s 206us/step - loss: 0.5479 - acc: 0.7794 - recall_m: 0.7995 - val_loss: 0.5412 - val_acc: 0.8206 - val_recall_m: 0.7005\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 43/100\n",
      "11934/11934 [==============================] - 2s 205us/step - loss: 0.5482 - acc: 0.7795 - recall_m: 0.7987 - val_loss: 0.5411 - val_acc: 0.8206 - val_recall_m: 0.7005\n",
      "Epoch 44/100\n",
      "11934/11934 [==============================] - 2s 202us/step - loss: 0.5479 - acc: 0.7800 - recall_m: 0.8050 - val_loss: 0.5410 - val_acc: 0.8206 - val_recall_m: 0.7005\n",
      "Epoch 45/100\n",
      "11934/11934 [==============================] - 2s 207us/step - loss: 0.5471 - acc: 0.7756 - recall_m: 0.7991 - val_loss: 0.5411 - val_acc: 0.8206 - val_recall_m: 0.7005\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 46/100\n",
      "11934/11934 [==============================] - 2s 204us/step - loss: 0.5498 - acc: 0.7760 - recall_m: 0.7979 - val_loss: 0.5409 - val_acc: 0.8206 - val_recall_m: 0.7005\n",
      "Epoch 47/100\n",
      "11934/11934 [==============================] - 3s 222us/step - loss: 0.5460 - acc: 0.7818 - recall_m: 0.8009 - val_loss: 0.5411 - val_acc: 0.8206 - val_recall_m: 0.7005\n",
      "Epoch 48/100\n",
      "11934/11934 [==============================] - 3s 216us/step - loss: 0.5477 - acc: 0.7784 - recall_m: 0.7973 - val_loss: 0.5412 - val_acc: 0.8206 - val_recall_m: 0.7005\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 49/100\n",
      "11934/11934 [==============================] - 3s 212us/step - loss: 0.5504 - acc: 0.7788 - recall_m: 0.8025 - val_loss: 0.5412 - val_acc: 0.8206 - val_recall_m: 0.7005\n",
      "Epoch 50/100\n",
      "11934/11934 [==============================] - 2s 209us/step - loss: 0.5479 - acc: 0.7767 - recall_m: 0.8037 - val_loss: 0.5411 - val_acc: 0.8206 - val_recall_m: 0.7005\n",
      "Epoch 51/100\n",
      "11934/11934 [==============================] - 2s 207us/step - loss: 0.5452 - acc: 0.7809 - recall_m: 0.7981 - val_loss: 0.5412 - val_acc: 0.8206 - val_recall_m: 0.7005\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 52/100\n",
      "11934/11934 [==============================] - 3s 210us/step - loss: 0.5462 - acc: 0.7834 - recall_m: 0.8051 - val_loss: 0.5412 - val_acc: 0.8206 - val_recall_m: 0.7005\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00052: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12a956f98>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DNN.fit(\n",
    "    x_resampled, y_resampled, batch_size=512, epochs=100,\\\n",
    "    validation_data=(x_val,y_val), verbose=1,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(monitor='recall_m',mode='max',\\\n",
    "                                      patience=16,verbose=1,\\\n",
    "                                      restore_best_weights=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(factor=0.5,patience=3,verbose=1)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T03:58:22.809505Z",
     "start_time": "2019-11-30T03:58:22.665880Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         NR.AhR: 0.86810\n"
     ]
    }
   ],
   "source": [
    "auc_te = roc_auc_score(y_te[target][rows_te], DNN.predict(x_te[rows_te]))\n",
    "print(\"%15s: %3.5f\" % (target, auc_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T03:58:22.892376Z",
     "start_time": "2019-11-30T03:58:22.811582Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['TN' 'FP']\n",
      " ['FN' 'TP']]\n",
      "[[437 100]\n",
      " [ 16  57]]\n"
     ]
    }
   ],
   "source": [
    "y_testing=y_te[target][~np.isnan(y_te[target])]\n",
    "y_hat_testing=DNN.predict_classes(x_te[rows_te])\n",
    "print(np.array([['TN','FP'],['FN','TP']]))\n",
    "print(confusion_matrix(y_testing,y_hat_testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T03:58:22.906002Z",
     "start_time": "2019-11-30T03:58:22.894482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.49565217391304345\n",
      "recall: 0.7808219178082192\n",
      "precision: 0.3630573248407643\n"
     ]
    }
   ],
   "source": [
    "print('f1:',f1_score(y_testing,y_hat_testing))\n",
    "print('recall:',recall_score(y_testing,y_hat_testing))\n",
    "print('precision:',precision_score(y_testing,y_hat_testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T03:58:22.918407Z",
     "start_time": "2019-11-30T03:58:22.908453Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    537\n",
       "1.0     73\n",
       "Name: NR.AhR, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_te[target][rows_te].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T03:58:22.924424Z",
     "start_time": "2019-11-30T03:58:22.920313Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8803278688524591"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "537/(537+73)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment to save model.  Last ROC_UAC = 0.86068"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T03:58:22.931305Z",
     "start_time": "2019-11-30T03:58:22.928004Z"
    }
   },
   "outputs": [],
   "source": [
    "# DNN.save('./models/first_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
